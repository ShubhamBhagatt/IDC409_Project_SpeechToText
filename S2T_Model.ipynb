{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6788e33f-baf1-4847-a993-a9ec85f7d7c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jiwer in /Users/perseus/anaconda3/lib/python3.11/site-packages (3.0.3)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from jiwer) (8.1.7)\n",
      "Requirement already satisfied: rapidfuzz<4,>=3 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from jiwer) (3.4.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#SPEECH TO TEXT\n",
    "!pip install jiwer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f00840-99c5-4609-824c-9f0694b759c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/perseus/anaconda3/lib/python3.11/site-packages (2.14.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.14.0 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (4.24.4)\n",
      "Requirement already satisfied: setuptools in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.59.2)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.14.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2.23.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/perseus/anaconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "##importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from jiwer import wer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a92e93f1-f98b-4f92-bcf7-7501fc0fd4bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_url = \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\"\n",
    "## extracting the data of LJspeech dataset using the keras in tensorflow\n",
    "## untar = True is used to extract the file if it is archived\n",
    "data_path = keras.utils.get_file(\"LJSpeech-1.1\", data_url, untar =True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19fc1209-1c52-4acf-8df5-58e7ae65ce58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LJ001-0001</td>\n",
       "      <td>Printing, in the only sense with which we are ...</td>\n",
       "      <td>Printing, in the only sense with which we are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LJ001-0002</td>\n",
       "      <td>in being comparatively modern.</td>\n",
       "      <td>in being comparatively modern.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LJ001-0003</td>\n",
       "      <td>For although the Chinese took impressions from...</td>\n",
       "      <td>For although the Chinese took impressions from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LJ001-0004</td>\n",
       "      <td>produced the block books, which were the immed...</td>\n",
       "      <td>produced the block books, which were the immed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LJ001-0005</td>\n",
       "      <td>the invention of movable metal letters in the ...</td>\n",
       "      <td>the invention of movable metal letters in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LJ001-0006</td>\n",
       "      <td>And it is worth mention in passing that, as an...</td>\n",
       "      <td>And it is worth mention in passing that, as an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LJ001-0007</td>\n",
       "      <td>the earliest book printed with movable types, ...</td>\n",
       "      <td>the earliest book printed with movable types, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LJ001-0008</td>\n",
       "      <td>has never been surpassed.</td>\n",
       "      <td>has never been surpassed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LJ001-0009</td>\n",
       "      <td>Printing, then, for our purpose, may be consid...</td>\n",
       "      <td>Printing, then, for our purpose, may be consid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LJ001-0010</td>\n",
       "      <td>Now, as all books not primarily intended as pi...</td>\n",
       "      <td>Now, as all books not primarily intended as pi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0                                                  1  \\\n",
       "0  LJ001-0001  Printing, in the only sense with which we are ...   \n",
       "1  LJ001-0002                     in being comparatively modern.   \n",
       "2  LJ001-0003  For although the Chinese took impressions from...   \n",
       "3  LJ001-0004  produced the block books, which were the immed...   \n",
       "4  LJ001-0005  the invention of movable metal letters in the ...   \n",
       "5  LJ001-0006  And it is worth mention in passing that, as an...   \n",
       "6  LJ001-0007  the earliest book printed with movable types, ...   \n",
       "7  LJ001-0008                          has never been surpassed.   \n",
       "8  LJ001-0009  Printing, then, for our purpose, may be consid...   \n",
       "9  LJ001-0010  Now, as all books not primarily intended as pi...   \n",
       "\n",
       "                                                   2  \n",
       "0  Printing, in the only sense with which we are ...  \n",
       "1                     in being comparatively modern.  \n",
       "2  For although the Chinese took impressions from...  \n",
       "3  produced the block books, which were the immed...  \n",
       "4  the invention of movable metal letters in the ...  \n",
       "5  And it is worth mention in passing that, as an...  \n",
       "6  the earliest book printed with movable types, ...  \n",
       "7                          has never been surpassed.  \n",
       "8  Printing, then, for our purpose, may be consid...  \n",
       "9  Now, as all books not primarily intended as pi...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavs_path = data_path + \"/wavs/\"\n",
    "metadata_path = data_path + \"/metadata.csv\"\n",
    "##converting the csv file to a dataframe using pandas\n",
    "metadata_df = pd.read_csv(metadata_path, sep = \"|\", header = None, quoting = 3)\n",
    "metadata_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc05abf9-83d5-4d61-b005-41ac66046496",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>normalized transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LJ009-0192</td>\n",
       "      <td>The dissection of executed criminals was aboli...</td>\n",
       "      <td>The dissection of executed criminals was aboli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LJ039-0194</td>\n",
       "      <td>All three of the firers in these tests</td>\n",
       "      <td>All three of the firers in these tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LJ016-0123</td>\n",
       "      <td>got hold of the step ladder used in lighting t...</td>\n",
       "      <td>got hold of the step ladder used in lighting t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file name                                      transcription  \\\n",
       "0  LJ009-0192  The dissection of executed criminals was aboli...   \n",
       "1  LJ039-0194             All three of the firers in these tests   \n",
       "2  LJ016-0123  got hold of the step ladder used in lighting t...   \n",
       "\n",
       "                            normalized transcription  \n",
       "0  The dissection of executed criminals was aboli...  \n",
       "1             All three of the firers in these tests  \n",
       "2  got hold of the step ladder used in lighting t...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metadata_df.columns = [\"file name\", \"transcription\", \"normalized transcription\"]\n",
    "##reshuffling the rows of the metadata df in a random order and not not\n",
    "\n",
    "metadata_df = metadata_df.sample(frac = 1).reset_index (drop = True)\n",
    "metadata_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf7e15c4-a9b8-4646-b04f-98cf429372f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the training dataframe :  {13}\n",
      "size of the test dataframe :  {13087}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## splitting the dataframe into two parts : training (90%), test (10%); using int to get an index at which to split\n",
    "split = int(len(metadata_df) *0.0010)\n",
    "df_train = metadata_df [:split]\n",
    "df_test = metadata_df[split:]\n",
    "print (\"size of the training dataframe : \",{len(df_train)})\n",
    "print (\"size of the test dataframe : \",{len(df_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa621121-7b40-45ad-90d2-4b500e08683e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!']\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "#defining a list of allowed vocabulary\n",
    "characters = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!\"]\n",
    "#converting the charactrs to integer values using keras; any character not in the list is given an empty string\n",
    "char_to_num = keras.layers.StringLookup(vocabulary = characters, oov_token = \"\")\n",
    "#converting the integer back to the character using keras, specifying it using invert\n",
    "num_to_char = keras.layers.StringLookup(vocabulary = char_to_num.get_vocabulary(), oov_token = \"\", invert = True)\n",
    "print (char_to_num.get_vocabulary())\n",
    "print(char_to_num.vocabulary_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b7b4e00-1358-4fd0-b8aa-38a808ed56ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting the frame length, frame step and forward fourier transform rate\n",
    "frame_length = 256\n",
    "frame_step = 160\n",
    "fft_length = 384\n",
    "#defining function for getting a spectrogram of the audio files and its label\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "def encode_single_sample (wav_file, label):\n",
    "  #reading the audio file\n",
    "  file = tf.io.read_file (wavs_path + wav_file + \".wav\")\n",
    "  #decoding the audio file using audio.decode_wav from the TensorFlow package to a float tensor\n",
    "  audio,_ = tf.audio.decode_wav(file)\n",
    "  #removing dimensions of size 1 from the tensor\n",
    "  audio = tf.squeeze(audio, axis = -1)\n",
    "  #changing the data type\n",
    "  audio = tf.cast(audio, tf.float32)\n",
    "  #converting the audio signal into a time frequency representation using Short Time Fourier Transfrom\n",
    "  spectrogram = tf.signal.stft (audio, frame_length = frame_length, frame_step = frame_step, fft_length = fft_length)\n",
    "  #calculating the magnitude of the spectrogram\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "  #normalizing the power\n",
    "  spectrogram = tf.math.pow(spectrogram, 0.5)\n",
    "  #performing the standardization of the spectrogram\n",
    "  means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)\n",
    "  stddev = tf.math.reduce_std(spectrogram, 1, keepdims=True)\n",
    "  spectrogram = (spectrogram - means)/(stddev - 1e-10)\n",
    "  #splitting the label character and converting it to a numerical representation\n",
    "  label = tf.strings.lower(label)\n",
    "  label = tf.strings.unicode_split(label, input_encoding = \"UTF-8\")\n",
    "  label = char_to_num(label)\n",
    "  return spectrogram, label\n",
    "batch_size = 32\n",
    "file_names = np.array(df_train[\"file name\"])\n",
    "transcriptions = np.array(df_train[\"normalized transcription\"])\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(( file_names,transcriptions))\n",
    "train_dataset = (train_dataset.map(encode_single_sample, num_parallel_calls = tf.data.AUTOTUNE).padded_batch(batch_size).prefetch(buffer_size = tf.data.AUTOTUNE))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((file_names, transcriptions))\n",
    "test_dataset = (test_dataset.map(encode_single_sample, num_parallel_calls = tf.data.AUTOTUNE).padded_batch(batch_size).prefetch(buffer_size = tf.data.AUTOTUNE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5df676ef-2ffc-4177-8a93-2610de6ae3bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#defining function for CTCloss; y_true--> target , y_pred--> predicted\n",
    "def CTCloss (y_true, y_pred):\n",
    "  #getting the shape of the tensor and extracting the first dimension\n",
    "  batch_len = tf.cast(tf.shape(y_true)[0], dtype = \"int64\")\n",
    "  #calculating the second dimension\n",
    "  input_length = tf.cast(tf.shape(y_pred)[1], dtype = \"int64\")\n",
    "  #calculating the length of the label sequence\n",
    "  label_length = tf.cast(tf.shape(y_true)[1], dtype = \"int64\")\n",
    "  #giving it shape (batch_len, 1), creating a 2D tensor with ones\n",
    "  input_length = input_length * tf.ones(shape = (batch_len, 1), dtype = \"int64\")\n",
    "  label_length = label_length * tf.ones(shape = (batch_len, 1), dtype = \"int64\")\n",
    "  #calculating the CTC loss\n",
    "  #keras is deeplearning framework(API) in the TensorFlow package\n",
    "  #the backend function does the mathematical operations on the tensors\n",
    "  loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "  return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39455e5a-0393-4b65-a9ef-d6dd111cd10c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"STT_Model\"\n",
      "______________________________________________________________________________________________________________\n",
      " Layer (type)                                    Output Shape                                Param #          \n",
      "==============================================================================================================\n",
      " input (InputLayer)                              [(None, None, 193)]                         0                \n",
      "                                                                                                              \n",
      " expanddim (Reshape)                             (None, None, 193, 1)                        0                \n",
      "                                                                                                              \n",
      " conv_1 (Conv2D)                                 (None, None, 97, 32)                        14432            \n",
      "                                                                                                              \n",
      " conv_1_bn (BatchNormalization)                  (None, None, 97, 32)                        128              \n",
      "                                                                                                              \n",
      " conv_1_relu (ReLU)                              (None, None, 97, 32)                        0                \n",
      "                                                                                                              \n",
      " conv_2 (Conv2D)                                 (None, None, 49, 32)                        236544           \n",
      "                                                                                                              \n",
      " conv_2_bn (BatchNormalization)                  (None, None, 49, 32)                        128              \n",
      "                                                                                                              \n",
      " conv_2_relu (ReLU)                              (None, None, 49, 32)                        0                \n",
      "                                                                                                              \n",
      " reshape_3 (Reshape)                             (None, None, 1568)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_1 (Bidirectional)                 (None, None, 1024)                          6395904          \n",
      "                                                                                                              \n",
      " dropout_15 (Dropout)                            (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_2 (Bidirectional)                 (None, None, 1024)                          4724736          \n",
      "                                                                                                              \n",
      " dropout_16 (Dropout)                            (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_3 (Bidirectional)                 (None, None, 1024)                          4724736          \n",
      "                                                                                                              \n",
      " dropout_17 (Dropout)                            (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_4 (Bidirectional)                 (None, None, 1024)                          4724736          \n",
      "                                                                                                              \n",
      " dropout_18 (Dropout)                            (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_5 (Bidirectional)                 (None, None, 1024)                          4724736          \n",
      "                                                                                                              \n",
      " dense_1 (Dense)                                 (None, None, 1024)                          1049600          \n",
      "                                                                                                              \n",
      " dense_1_relu (ReLU)                             (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " dropout_19 (Dropout)                            (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " dense_3 (Dense)                                 (None, None, 31)                            31775            \n",
      "                                                                                                              \n",
      "==============================================================================================================\n",
      "Total params: 26627455 (101.58 MB)\n",
      "Trainable params: 26627327 (101.58 MB)\n",
      "Non-trainable params: 128 (512.00 Byte)\n",
      "______________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##defining a neural network using keras\n",
    "##inputdim = dimension of the input\n",
    "##outputdim = dimension of the input\n",
    "##rnn layers = number of recurrent layers in the network\n",
    "##rnn units = number of neurons\n",
    "def draft_model (inputdim, outputdim, rnn_layers = 5, rnn_units = 128):\n",
    "    #allowing the input to have variable length \n",
    "  input_spectrogram = layers.Input ((None, inputdim), name = \"input\")\n",
    "#reshaping \n",
    "  x = layers.Reshape((-1, inputdim, 1), name = \"expanddim\")(input_spectrogram)\n",
    "    #adding a convolutional layer\n",
    "  x = layers.Conv2D( filters = 32, kernel_size = [11,41], strides = [2,2], padding = \"same\", use_bias = False, name = \"conv_1\",)(x)\n",
    "#normalizing the layers \n",
    "  x = layers.BatchNormalization(name = \"conv_1_bn\")(x)\n",
    "    #adding non-linearity using ReLU (Rectified Linear Unit)\n",
    "  x = layers.ReLU(name = \"conv_1_relu\")(x)\n",
    "#adding convolutional layer\n",
    "  x = layers.Conv2D(filters = 32, kernel_size =[11,21], strides = [1,2], padding = \"same\", use_bias = False, name = \"conv_2\")(x)\n",
    "  x = layers.BatchNormalization(name =\"conv_2_bn\")(x)\n",
    "  x = layers.ReLU(name = \"conv_2_relu\")(x)\n",
    "    #falttening the tensor into a 2D tensor\n",
    "  x = layers.Reshape((-1, x.shape[-2]*x.shape[-1]))(x)\n",
    "#Building a stack of birectional GRU (gated recurrent unit) layers  \n",
    "  for i in range (1, rnn_layers + 1):\n",
    "    recurrent = layers.GRU(units= rnn_units, activation = \"tanh\", recurrent_activation = \"sigmoid\", use_bias = True, return_sequences = True,\n",
    "                           reset_after = True, name = f\"gru_{i}\",)\n",
    "    x = layers.Bidirectional(recurrent, name = f\"bidirectional_{i}\", merge_mode=\"concat\")(x)\n",
    "    if i < rnn_layers:\n",
    "      x = layers.Dropout(rate= 0.5)(x)\n",
    "    #adding a dense layer to output\n",
    "  x = layers.Dense(units = rnn_units * 2, name = \"dense_1\")(x)\n",
    "  x = layers.ReLU(name = \"dense_1_relu\")(x)\n",
    "    #preventing overfitting and adding noise \n",
    "  x = layers.Dropout ( rate = 0.5 )(x)\n",
    "  output = layers.Dense(units = outputdim + 1, activation = \"softmax\")(x)\n",
    "    #creating a model and naming it \n",
    "  model = keras.Model(input_spectrogram, output, name = \"STT_Model\")\n",
    "#adding an optimizer, Adam, for training of model\n",
    "  opt = Adam(learning_rate= 1e-4) \n",
    "  model.compile(optimizer = opt, loss= CTCloss)\n",
    "  return model\n",
    "fft_length = 384\n",
    "#creating an instance of the model\n",
    "model = draft_model(inputdim = fft_length // 2 + 1, outputdim= char_to_num.vocabulary_size(), rnn_units = 512,)\n",
    "model.summary(line_length = 110)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0ea17b1-6b7c-4a30-802e-a38adcf5ebe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#decoding the predictions made by the model \n",
    "def decode_batch_predictions (pred):\n",
    "    #calculating the length of input sequence in a sample\n",
    "  input_len = np.ones(pred.shape[0]) * pred.shape [1]\n",
    "#decoding the CTC predictions using keras ctc_decode backend function; using the greedy decoder\n",
    "  results = keras.backend.ctc_decode(pred, input_length = input_len, greedy = True)[0][0]\n",
    "    #initiallizing list for the output\n",
    "  output_text =[]\n",
    "  for result in results :\n",
    "        #converting to a NumPy array and then decoding as a UTF-8 string\n",
    "    result = tf.strings.reduce_join(num_to_char(result)).numpy().decode(\"utf-8\")\n",
    "    output_text.append(result)\n",
    "  return output_text\n",
    "#defining a custom callback class to call in at a specific point in the model training to perfom an action \n",
    "class CallbackEval(keras.callbacks.Callback):\n",
    "#initializing the method for the class; self --> instance of the class \n",
    "  def __init__(self, dataset):\n",
    "        #calling the Kears callback function using the super function\n",
    "    super().__init__()\n",
    "    self.dataset = dataset\n",
    "    #defining a specific callback method using at the end of each epoch \n",
    "  def on_epoch_end(self, epoch: int , logs = None):\n",
    "     predictions = []\n",
    "     targets = []\n",
    "     for batch in self.dataset:\n",
    "            #unloading the input (X) and the target (y), into batch \n",
    "      X, y = batch\n",
    "    #using the predict function to get the precditions from the model \n",
    "      batch_predictions = model.predict(X)\n",
    "        #decoding the predictions \n",
    "      batch_predictions = decode_batch_predictions (batch_predictions)\n",
    "    #appending the predictions to the list \n",
    "      predictions.extend(batch_predictions)\n",
    "      for label in y :\n",
    "       label = (tf.strings.reduce_join (num_to_char(label)).numpy().decode(\"utf-8\"))\n",
    "       targets.append (label)\n",
    "        #using the wer function in jiwer to get the word error rate \n",
    "     wer_score = wer (targets, predictions)\n",
    "     print (\".\" *100)\n",
    "     print (f\"Word error rate : { wer_score: .4f}\")\n",
    "     print (\".\"*100)\n",
    "   #printing two of the predictions at random\n",
    "     for i in np.random.randint (0, len(predictions),2):\n",
    "      print (\"target : \", (targets[i]))\n",
    "      print (\"prediction: \", (predictions[i]))\n",
    "      print (\".\" *100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a04b552b-8cc9-4c32-befa-304e8fc4977f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 4s 4s/steploss: 568.65\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "target :  mentionedanyproposedvisitbymrnixontodallas\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target :  andthemarchelevennineteensixtythreeissueofthemilitant\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "1/1 [==============================] - 31s 31s/step - loss: 568.6530 - val_loss: 844.1586\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 5s 5s/steploss: 366.33\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "target :  thedistancebetweenthepointontheseatandthedoorwastwentyseveninches\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target :  andthemarchelevennineteensixtythreeissueofthemilitant\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "1/1 [==============================] - 33s 33s/step - loss: 366.3338 - val_loss: 649.8871\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 5s 5s/steploss: 399.40\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "target :  underthestewardtherewerecaptainsofwardschoseninthesamewayandperforminganalogousduties\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target :  thepresidenthadspokenearlierthatdayattheairforceacademyincoloradospringscolorado\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "1/1 [==============================] - 33s 33s/step - loss: 399.4012 - val_loss: 587.5914\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 5s 5s/steploss: 416.27\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "target :  underthestewardtherewerecaptainsofwardschoseninthesamewayandperforminganalogousduties\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target :  thedistancebetweenthepointontheseatandthedoorwastwentyseveninches\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "1/1 [==============================] - 39s 39s/step - loss: 416.2732 - val_loss: 543.1967\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 5s 5s/steploss: 385.39\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "target :  mrsrandleestimatedthatthepackagewasapproximatelytwentyeightincheslongandabouteightincheswide\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target :  rumourevenwentsofarastoassertthatamongthespectatorswereseveralwomendisguisedinmalehabiliments\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "1/1 [==============================] - 37s 37s/step - loss: 385.3974 - val_loss: 500.2404\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 5s 5s/steploss: 350.18\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "target :  unlessasystemisestablishedforthefrequentformalreviewofactivitiesthereunderinthisregard\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target :  underthestewardtherewerecaptainsofwardschoseninthesamewayandperforminganalogousduties\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "1/1 [==============================] - 38s 38s/step - loss: 350.1885 - val_loss: 469.6071\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 5s 5s/steploss: 318.42\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "target :  thegreyhoundbusstationatlamarandjacksonstreetswhereoswaldenteredwhaley'scab\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target :  thegreyhoundbusstationatlamarandjacksonstreetswhereoswaldenteredwhaley'scab\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "1/1 [==============================] - 33s 33s/step - loss: 318.4245 - val_loss: 459.8325\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 5s 5s/steploss: 310.65\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "target :  thepresidenthadspokenearlierthatdayattheairforceacademyincoloradospringscolorado\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target :  fromlovefieldtheroutepassedthroughaportionofsuburbandallas\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "1/1 [==============================] - 36s 36s/step - loss: 310.6579 - val_loss: 467.6475\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 6s 6s/steploss: 330.55\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "target :  unlessasystemisestablishedforthefrequentformalreviewofactivitiesthereunderinthisregard\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target :  rumourevenwentsofarastoassertthatamongthespectatorswereseveralwomendisguisedinmalehabiliments\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "1/1 [==============================] - 36s 36s/step - loss: 330.5558 - val_loss: 419.0762\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 6s 6s/steploss: 325.27\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "target :  thecreationofausefulinstrumentformanultimatelycomes\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target :  thepresidenthadspokenearlierthatdayattheairforceacademyincoloradospringscolorado\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "1/1 [==============================] - 37s 37s/step - loss: 325.2711 - val_loss: 345.1988\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 5s 5s/steploss: 296.18\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "target :  andthemarchelevennineteensixtythreeissueofthemilitant\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target :  theweeklyintroductionoffoodtowhichishallpresentlyreferformedthebasisofluxuriousbanquetswasheddownbyliquor\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "1/1 [==============================] - 35s 35s/step - loss: 296.1860 - val_loss: 314.3076\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 5s 5s/steploss: 288.81\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "target :  fromlovefieldtheroutepassedthroughaportionofsuburbandallas\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target :  andthemarchelevennineteensixtythreeissueofthemilitant\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "1/1 [==============================] - 37s 37s/step - loss: 288.8198 - val_loss: 317.9211\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 5s 5s/steploss: 297.35\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "target :  fromlovefieldtheroutepassedthroughaportionofsuburbandallas\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target :  othersthathehadhadextraordinaryluckasagolddiggerhadhiswestendandlittleinformedassociatesfollowedhimintothecity\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "1/1 [==============================] - 39s 39s/step - loss: 297.3599 - val_loss: 326.6367\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 5s 5s/steploss: 305.56\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "target :  rumourevenwentsofarastoassertthatamongthespectatorswereseveralwomendisguisedinmalehabiliments\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target :  thecreationofausefulinstrumentformanultimatelycomes\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "1/1 [==============================] - 36s 36s/step - loss: 305.5681 - val_loss: 325.7033\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 5s 5s/steploss: 304.52\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "target :  fromlovefieldtheroutepassedthroughaportionofsuburbandallas\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target :  underthestewardtherewerecaptainsofwardschoseninthesamewayandperforminganalogousduties\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "1/1 [==============================] - 36s 36s/step - loss: 304.5268 - val_loss: 313.3293\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 5s 5s/steploss: 294.53\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "target :  thepresidenthadspokenearlierthatdayattheairforceacademyincoloradospringscolorado\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target :  rumourevenwentsofarastoassertthatamongthespectatorswereseveralwomendisguisedinmalehabiliments\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "1/1 [==============================] - 40s 40s/step - loss: 294.5368 - val_loss: 295.2806\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 5s 5s/steploss: 283.93\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "target :  andthemarchelevennineteensixtythreeissueofthemilitant\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target :  unlessasystemisestablishedforthefrequentformalreviewofactivitiesthereunderinthisregard\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "1/1 [==============================] - 35s 35s/step - loss: 283.9375 - val_loss: 281.1693\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 5s 5s/steploss: 278.44\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "target :  underthestewardtherewerecaptainsofwardschoseninthesamewayandperforminganalogousduties\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target :  thepresidenthadspokenearlierthatdayattheairforceacademyincoloradospringscolorado\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "1/1 [==============================] - 37s 37s/step - loss: 278.4441 - val_loss: 276.8314\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 5s 5s/steploss: 281.06\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "target :  thegreyhoundbusstationatlamarandjacksonstreetswhereoswaldenteredwhaley'scab\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target :  fromlovefieldtheroutepassedthroughaportionofsuburbandallas\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "1/1 [==============================] - 36s 36s/step - loss: 281.0667 - val_loss: 278.7164\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 6s 6s/steploss: 286.96\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "target :  thegreyhoundbusstationatlamarandjacksonstreetswhereoswaldenteredwhaley'scab\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target :  mentionedanyproposedvisitbymrnixontodallas\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "1/1 [==============================] - 36s 36s/step - loss: 286.9629 - val_loss: 278.3482\n"
     ]
    }
   ],
   "source": [
    "#specifying the number of epochs for training \n",
    "epochs = 20\n",
    "#calling the custom Callbackeval function \n",
    "validation_callback = CallbackEval(test_dataset)\n",
    "#training the model using the fit function in keras\n",
    "history = model.fit(train_dataset, validation_data= test_dataset, epochs= epochs, callbacks = [validation_callback],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85b239df-0316-4839-9868-6c9271e85bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Printing random samples:\n",
      "Random Index: 0\n",
      "target :  thedissectionofexecutedcriminalswasabolishedsoonafterthediscoveryofthecrimeofburking\n",
      "prediction:  yutytkyptpiptukpkptptukptptktktykatytktypykykypytykypkpkp!hadktutubdb\n",
      "....................................................................................................\n",
      "Random Index: 9\n",
      "target :  wereelectedtoinspecttheprisonsfrequentlytoexaminetheprisonershearcomplaintsandcheckabuses\n",
      "prediction:  tyktktypkpkykypypytkpkpkutkpkyktktpkytypkukytktpktypktuykykptptypwybd\n",
      "....................................................................................................\n",
      "target : tothegreatsurpriseofallwhowitnessedthisdreadfulscene\n",
      "prediction:  tykpypypkpkpyp?typtptykytpt!a!yumud\n",
      "....................................................................................................\n",
      "target : tothegreatsurpriseofallwhowitnessedthisdreadfulscene\n",
      "prediction:  tykpypypkpkpyp?typtptykytpt!a!yumud\n",
      "....................................................................................................\n"
     ]
    }
   ],
   "source": [
    "#checking for the predictions in the test_dataset \n",
    "predictions = []\n",
    "targets = []\n",
    "for batch in test_dataset :\n",
    "  X, y = batch\n",
    "  batch_predictions = model.predict(X)\n",
    "  batch_predictions = decode_batch_predictions (batch_predictions)\n",
    "  predictions.extend(batch_predictions)\n",
    "  for label in y :\n",
    "       label = (tf.strings.reduce_join (num_to_char(label)).numpy().decode(\"utf-8\"))\n",
    "       targets.append (label)\n",
    "wer_score = wer (targets, predictions)\n",
    "print (\".\" *100)\n",
    "print (f\"Word error rate : { wer_score: .4f}\")\n",
    "print (\".\"*100)\n",
    "print (\".\" *100)\n",
    "# Check if the loop is being executed\n",
    "print(\"Printing random samples:\")\n",
    "for i in range(2):\n",
    "    random_index = np.random.randint(0, len(predictions))\n",
    "    print(\"Random Index:\", random_index)\n",
    "    print(\"target : \", (targets[random_index]))\n",
    "    print(\"prediction: \", (predictions[random_index]))\n",
    "    print(\".\" * 100)\n",
    "for i in np.random.randint (0, len(predictions),2):\n",
    "      print (f\"target : {targets[i]}\")\n",
    "      print (f\"prediction:  {predictions[i]}\")\n",
    "      print (\".\" *100)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "eeffd8c8-378a-4b6d-bc20-618f26da43fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#saving the model and its assets\n",
    "model.save(\"stt.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbc0fbb-ad94-4b6e-8fa4-4be1f47721f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
