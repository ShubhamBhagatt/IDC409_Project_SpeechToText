{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6946f604-a366-47e1-a745-02b4628e9f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jiwer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd4eba9f-d52b-467c-9030-414aa4cebf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "##importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9e2419-839b-479f-89cf-526a6a8b0d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f3c190-05d0-4104-85a2-143b0d27861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_url = \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\"\n",
    "# ## extracting the data of LJspeech dataset using the keras in tensorflow\n",
    "# ## untar = True is used to extract the file if it is archived\n",
    "# data_path = keras.utils.get_file(\"LJSpeech-1.1\", data_url, untar =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c774e2d-cda1-4426-92cc-4e34e4572393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LJ001-0001</td>\n",
       "      <td>Printing, in the only sense with which we are ...</td>\n",
       "      <td>Printing, in the only sense with which we are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LJ001-0002</td>\n",
       "      <td>in being comparatively modern.</td>\n",
       "      <td>in being comparatively modern.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LJ001-0003</td>\n",
       "      <td>For although the Chinese took impressions from...</td>\n",
       "      <td>For although the Chinese took impressions from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LJ001-0004</td>\n",
       "      <td>produced the block books, which were the immed...</td>\n",
       "      <td>produced the block books, which were the immed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LJ001-0005</td>\n",
       "      <td>the invention of movable metal letters in the ...</td>\n",
       "      <td>the invention of movable metal letters in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LJ001-0006</td>\n",
       "      <td>And it is worth mention in passing that, as an...</td>\n",
       "      <td>And it is worth mention in passing that, as an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LJ001-0007</td>\n",
       "      <td>the earliest book printed with movable types, ...</td>\n",
       "      <td>the earliest book printed with movable types, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LJ001-0008</td>\n",
       "      <td>has never been surpassed.</td>\n",
       "      <td>has never been surpassed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LJ001-0009</td>\n",
       "      <td>Printing, then, for our purpose, may be consid...</td>\n",
       "      <td>Printing, then, for our purpose, may be consid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LJ001-0010</td>\n",
       "      <td>Now, as all books not primarily intended as pi...</td>\n",
       "      <td>Now, as all books not primarily intended as pi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0                                                  1  \\\n",
       "0  LJ001-0001  Printing, in the only sense with which we are ...   \n",
       "1  LJ001-0002                     in being comparatively modern.   \n",
       "2  LJ001-0003  For although the Chinese took impressions from...   \n",
       "3  LJ001-0004  produced the block books, which were the immed...   \n",
       "4  LJ001-0005  the invention of movable metal letters in the ...   \n",
       "5  LJ001-0006  And it is worth mention in passing that, as an...   \n",
       "6  LJ001-0007  the earliest book printed with movable types, ...   \n",
       "7  LJ001-0008                          has never been surpassed.   \n",
       "8  LJ001-0009  Printing, then, for our purpose, may be consid...   \n",
       "9  LJ001-0010  Now, as all books not primarily intended as pi...   \n",
       "\n",
       "                                                   2  \n",
       "0  Printing, in the only sense with which we are ...  \n",
       "1                     in being comparatively modern.  \n",
       "2  For although the Chinese took impressions from...  \n",
       "3  produced the block books, which were the immed...  \n",
       "4  the invention of movable metal letters in the ...  \n",
       "5  And it is worth mention in passing that, as an...  \n",
       "6  the earliest book printed with movable types, ...  \n",
       "7                          has never been surpassed.  \n",
       "8  Printing, then, for our purpose, may be consid...  \n",
       "9  Now, as all books not primarily intended as pi...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"C:\\\\Users\\\\ASUS\\\\.keras\\\\datasets\\\\LJSpeech-1_extracted\\\\\"\n",
    "wavs_path = data_path + \"/LJSpeech-1.1/wavs/\"\n",
    "metadata_path = data_path + \"/LJSpeech-1.1/metadata.csv\"\n",
    "##converting the csv file to a dataframe using pandas\n",
    "metadata_df = pd.read_csv(metadata_path, sep = \"|\", header = None, quoting = 3)\n",
    "metadata_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "903dd194-2f3a-4e72-823c-6b8615325f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>normalized transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LJ029-0131</td>\n",
       "      <td>The building overlooks Dealey Plaza, an attrac...</td>\n",
       "      <td>The building overlooks Dealey Plaza, an attrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LJ011-0211</td>\n",
       "      <td>when indictments were preferred against both b...</td>\n",
       "      <td>when indictments were preferred against both b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LJ021-0162</td>\n",
       "      <td>What may be necessary for those countries is n...</td>\n",
       "      <td>What may be necessary for those countries is n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file name                                      transcription  \\\n",
       "0  LJ029-0131  The building overlooks Dealey Plaza, an attrac...   \n",
       "1  LJ011-0211  when indictments were preferred against both b...   \n",
       "2  LJ021-0162  What may be necessary for those countries is n...   \n",
       "\n",
       "                            normalized transcription  \n",
       "0  The building overlooks Dealey Plaza, an attrac...  \n",
       "1  when indictments were preferred against both b...  \n",
       "2  What may be necessary for those countries is n...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.columns = [\"file name\", \"transcription\", \"normalized transcription\"]\n",
    "##reshuffling the rows of the metadata df in a random order and not not\n",
    "\n",
    "metadata_df = metadata_df.sample(frac = 1).reset_index (drop = True)\n",
    "metadata_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65f23c28-93b5-4f29-86ae-6d25d82a0aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the training dataframe :  {65}\n",
      "size of the test dataframe :  {13035}\n"
     ]
    }
   ],
   "source": [
    "## splitting the dataframe into two parts : training and test; using int to get an index at which to split\n",
    "split = int(len(metadata_df) *0.005)\n",
    "df_train = metadata_df [:split]\n",
    "df_test = metadata_df[split:]\n",
    "print (\"size of the training dataframe : \",{len(df_train)})\n",
    "print (\"size of the test dataframe : \",{len(df_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89325021-693b-4b29-86a4-8f624b003fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!', ' ']\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "#defining a list of allowed vocabulary\n",
    "characters = [x for x in \"abcdefghijklmnopqrstuvwxyz'?! \"]\n",
    "#converting the charactrs to integer values using keras; any character not in the list is given an empty string\n",
    "char_to_num = keras.layers.StringLookup(vocabulary = characters, oov_token = \"\")\n",
    "#converting the integer back to the character using keras, specifying it using invert\n",
    "num_to_char = keras.layers.StringLookup(vocabulary = char_to_num.get_vocabulary(), oov_token = \"\", invert = True)\n",
    "print (char_to_num.get_vocabulary())\n",
    "print(char_to_num.vocabulary_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b870853-ffda-437e-97c2-2320166afb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Very imp add in slide\n",
    "\n",
    "# setting the frame length, frame step and forward fourier transform rate\n",
    "frame_length = 256\n",
    "frame_step = 160\n",
    "fft_length = 384\n",
    "#defining function for getting a spectrogram of the audio files and its label\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "def encode_single_sample (wav_file, label):\n",
    "  #reading the audio file\n",
    "  file = tf.io.read_file (wavs_path + wav_file + \".wav\")\n",
    "  #decoding the audio file using audio.decode_wav from the TensorFlow package to a float tensor\n",
    "  audio,_ = tf.audio.decode_wav(file)\n",
    "  #removing dimensions of size 1 from the tensor\n",
    "  audio = tf.squeeze(audio, axis = -1)\n",
    "  #changing the data type\n",
    "  audio = tf.cast(audio, tf.float32)\n",
    "  #converting the audio signal into a time frequency representation using Short Time Fourier Transfrom\n",
    "  spectrogram = tf.signal.stft (audio, frame_length = frame_length, frame_step = frame_step, fft_length = fft_length)\n",
    "  #calculating the magnitude of the spectrogram\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "  #normalizing the power\n",
    "  spectrogram = tf.math.pow(spectrogram, 0.5)\n",
    "  #performing the standardization of the spectrogram\n",
    "  means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)\n",
    "  stddev = tf.math.reduce_std(spectrogram, 1, keepdims=True)\n",
    "  spectrogram = (spectrogram - means)/(stddev - 1e-10)\n",
    "  #splitting the label character and converting it to a numerical representation\n",
    "  label = tf.strings.lower(label)\n",
    "  label = tf.strings.unicode_split(label, input_encoding = \"UTF-8\")\n",
    "  label = char_to_num(label)\n",
    "  return spectrogram, label\n",
    "batch_size = 32\n",
    "file_names = np.array(df_train[\"file name\"])\n",
    "transcriptions = np.array(df_train[\"normalized transcription\"])\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(( file_names,transcriptions))\n",
    "train_dataset = (train_dataset.map(encode_single_sample, num_parallel_calls = tf.data.AUTOTUNE).padded_batch(batch_size).prefetch(buffer_size = tf.data.AUTOTUNE))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((file_names, transcriptions))\n",
    "test_dataset = (test_dataset.map(encode_single_sample, num_parallel_calls = tf.data.AUTOTUNE).padded_batch(batch_size).prefetch(buffer_size = tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c51f984-9444-4725-99a4-e9d60813a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function for CTCloss; y_true--> target , y_pred--> predicted\n",
    "def CTCloss (y_true, y_pred):\n",
    "  #getting the shape of the tensor and extracting the first dimension\n",
    "  batch_len = tf.cast(tf.shape(y_true)[0], dtype = \"int64\")\n",
    "  #calculating the second dimension\n",
    "  input_length = tf.cast(tf.shape(y_pred)[1], dtype = \"int64\")\n",
    "  #calculating the length of the label sequence\n",
    "  label_length = tf.cast(tf.shape(y_true)[1], dtype = \"int64\")\n",
    "  #giving it shape (batch_len, 1), creating a 2D tensor with ones\n",
    "  input_length = input_length * tf.ones(shape = (batch_len, 1), dtype = \"int64\")\n",
    "  label_length = label_length * tf.ones(shape = (batch_len, 1), dtype = \"int64\")\n",
    "  #calculating the CTC loss\n",
    "  #keras is deeplearning framework(API) in the TensorFlow package\n",
    "  #the backend function does the mathematical operations on the tensors\n",
    "  loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1057bc87-9dfb-4ce0-8230-627a4e4fa2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"STT_Model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"STT_Model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                   </span>┃<span style=\"font-weight: bold\"> Output Shape                        </span>┃<span style=\"font-weight: bold\">             Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">193</span>)                   │                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ expanddim (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">193</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ conv_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │              <span style=\"color: #00af00; text-decoration-color: #00af00\">14,432</span> │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ conv_1_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ conv_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ conv_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">236,544</span> │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ conv_2_bn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │                 <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ conv_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1568</span>)                  │                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,395,904</span> │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                  │                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,724,736</span> │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                  │                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,724,736</span> │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                  │                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,724,736</span> │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                  │                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ bidirectional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,724,736</span> │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ dense_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                  │                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                  │                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">32,800</span> │\n",
       "└────────────────────────────────────────────────┴─────────────────────────────────────┴─────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m            Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input (\u001b[38;5;33mInputLayer\u001b[0m)                             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m193\u001b[0m)                   │                   \u001b[38;5;34m0\u001b[0m │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ expanddim (\u001b[38;5;33mReshape\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m193\u001b[0m, \u001b[38;5;34m1\u001b[0m)                │                   \u001b[38;5;34m0\u001b[0m │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ conv_1 (\u001b[38;5;33mConv2D\u001b[0m)                                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │              \u001b[38;5;34m14,432\u001b[0m │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ conv_1_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │                 \u001b[38;5;34m128\u001b[0m │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ conv_1_relu (\u001b[38;5;33mReLU\u001b[0m)                             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │                   \u001b[38;5;34m0\u001b[0m │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ conv_2 (\u001b[38;5;33mConv2D\u001b[0m)                                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m236,544\u001b[0m │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ conv_2_bn (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │                 \u001b[38;5;34m128\u001b[0m │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ conv_2_relu (\u001b[38;5;33mReLU\u001b[0m)                             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │                   \u001b[38;5;34m0\u001b[0m │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1568\u001b[0m)                  │                   \u001b[38;5;34m0\u001b[0m │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                  │           \u001b[38;5;34m6,395,904\u001b[0m │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                  │                   \u001b[38;5;34m0\u001b[0m │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                  │           \u001b[38;5;34m4,724,736\u001b[0m │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                  │                   \u001b[38;5;34m0\u001b[0m │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                  │           \u001b[38;5;34m4,724,736\u001b[0m │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                  │                   \u001b[38;5;34m0\u001b[0m │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                  │           \u001b[38;5;34m4,724,736\u001b[0m │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                  │                   \u001b[38;5;34m0\u001b[0m │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ bidirectional_5 (\u001b[38;5;33mBidirectional\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                  │           \u001b[38;5;34m4,724,736\u001b[0m │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                  │           \u001b[38;5;34m1,049,600\u001b[0m │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ dense_1_relu (\u001b[38;5;33mReLU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                  │                   \u001b[38;5;34m0\u001b[0m │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                  │                   \u001b[38;5;34m0\u001b[0m │\n",
       "├────────────────────────────────────────────────┼─────────────────────────────────────┼─────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                    │              \u001b[38;5;34m32,800\u001b[0m │\n",
       "└────────────────────────────────────────────────┴─────────────────────────────────────┴─────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,628,480</span> (101.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,628,480\u001b[0m (101.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,628,352</span> (101.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,628,352\u001b[0m (101.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##defining a neural network using keras\n",
    "##inputdim = dimension of the input\n",
    "##outputdim = dimension of the input\n",
    "##rnn layers = number of recurrent layers in the network\n",
    "##rnn units = number of neurons\n",
    "def draft_model (inputdim, outputdim, rnn_layers = 5, rnn_units = 128):\n",
    "    #allowing the input to have variable length \n",
    "  input_spectrogram = layers.Input ((None, inputdim), name = \"input\")\n",
    "#reshaping \n",
    "  x = layers.Reshape((-1, inputdim, 1), name = \"expanddim\")(input_spectrogram)\n",
    "    #adding a convolutional layer\n",
    "  x = layers.Conv2D( filters = 32, kernel_size = [11,41], strides = [2,2], padding = \"same\", use_bias = False, name = \"conv_1\",)(x)\n",
    "#normalizing the layers \n",
    "  x = layers.BatchNormalization(name = \"conv_1_bn\")(x)\n",
    "    #adding non-linearity using ReLU (Rectified Linear Unit)\n",
    "  x = layers.ReLU(name = \"conv_1_relu\")(x)\n",
    "#adding convolutional layer\n",
    "  x = layers.Conv2D(filters = 32, kernel_size =[11,21], strides = [1,2], padding = \"same\", use_bias = False, name = \"conv_2\")(x)\n",
    "  x = layers.BatchNormalization(name =\"conv_2_bn\")(x)\n",
    "  x = layers.ReLU(name = \"conv_2_relu\")(x)\n",
    "    #falttening the tensor into a 2D tensor\n",
    "  x = layers.Reshape((-1, x.shape[-2]*x.shape[-1]))(x)\n",
    "#Building a stack of birectional GRU (gated recurrent unit) layers  \n",
    "  for i in range (1, rnn_layers + 1):\n",
    "    recurrent = layers.GRU(units= rnn_units, activation = \"tanh\", recurrent_activation = \"sigmoid\", use_bias = True, return_sequences = True,\n",
    "                           reset_after = True, name = f\"gru_{i}\",)\n",
    "    x = layers.Bidirectional(recurrent, name = f\"bidirectional_{i}\", merge_mode=\"concat\")(x)\n",
    "    if i < rnn_layers:\n",
    "      x = layers.Dropout(rate= 0.5)(x)\n",
    "    #adding a dense layer to output\n",
    "  x = layers.Dense(units = rnn_units * 2, name = \"dense_1\")(x)\n",
    "  x = layers.ReLU(name = \"dense_1_relu\")(x)\n",
    "    #preventing overfitting and adding noise \n",
    "  x = layers.Dropout ( rate = 0.5 )(x)\n",
    "  output = layers.Dense(units = outputdim + 1, activation = \"softmax\")(x)\n",
    "    #creating a model and naming it \n",
    "  model = keras.Model(input_spectrogram, output, name = \"STT_Model\")\n",
    "#adding an optimizer, Adam, for training of model\n",
    "  opt = Adam(learning_rate= 1e-4) \n",
    "  model.compile(optimizer = opt, loss= CTCloss)\n",
    "  return model\n",
    "fft_length = 384\n",
    "#creating an instance of the model\n",
    "model = draft_model(inputdim = fft_length // 2 + 1, outputdim= char_to_num.vocabulary_size(), rnn_units = 512,)\n",
    "model.summary(line_length = 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21bb6034-b2bf-4344-9008-3546f83b1a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoding the predictions made by the model \n",
    "def decode_batch_predictions (pred):\n",
    "    #calculating the length of input sequence in a sample\n",
    "  input_len = np.ones(pred.shape[0]) * pred.shape [1]\n",
    "#decoding the CTC predictions using keras ctc_decode backend function; using the greedy decoder\n",
    "  results = keras.backend.ctc_decode(pred, input_length = input_len, greedy = True)[0][0]\n",
    "    #initiallizing list for the output\n",
    "  output_text =[]\n",
    "  for result in results :\n",
    "        #converting to a NumPy array and then decoding as a UTF-8 string\n",
    "    result = tf.strings.reduce_join(num_to_char(result)).numpy().decode(\"utf-8\")\n",
    "    output_text.append(result)\n",
    "  return output_text\n",
    "#defining a custom callback class to call in at a specific point in the model training to perfom an action \n",
    "class CallbackEval(keras.callbacks.Callback):\n",
    "#initializing the method for the class; self --> instance of the class \n",
    "  def __init__(self, dataset):\n",
    "        #calling the Kears callback function using the super function\n",
    "    super().__init__()\n",
    "    self.dataset = dataset\n",
    "    #defining a specific callback method using at the end of each epoch \n",
    "  def on_epoch_end(self, epoch: int , logs = None):\n",
    "     predictions = []\n",
    "     targets = []\n",
    "     for batch in self.dataset:\n",
    "            #unloading the input (X) and the target (y), into batch \n",
    "      X, y = batch\n",
    "    #using the predict function to get the precditions from the model \n",
    "      batch_predictions = model.predict(X)\n",
    "        #decoding the predictions \n",
    "      batch_predictions = decode_batch_predictions (batch_predictions)\n",
    "    #appending the predictions to the list \n",
    "      predictions.extend(batch_predictions)\n",
    "      for label in y :\n",
    "       label = (tf.strings.reduce_join (num_to_char(label)).numpy().decode(\"utf-8\"))\n",
    "       targets.append (label)\n",
    "        #using the wer function in jiwer to get the word error rate \n",
    "     wer_score = wer (targets, predictions)\n",
    "     print (\".\" *100)\n",
    "     print (f\"Word error rate : { wer_score: .4f}\")\n",
    "     print (\".\"*100)\n",
    "   #printing two of the predictions at random\n",
    "     for i in np.random.randint (0, len(predictions),2):\n",
    "      print (\"target : \", (targets[i]))\n",
    "      print (\"prediction: \", (predictions[i]))\n",
    "      print (\".\" *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a0a1d19-833d-4069-a2f8-a32f206ee366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\backend.py:666: The name tf.nn.ctc_loss is deprecated. Please use tf.compat.v1.nn.ctc_loss instead.\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25s/step - loss: 1624.4225\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "target :  another person who saw the assassin as the shots were fired was amos l euins age fifteen\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target :  the president is head of state chief executive commander in chief and leader of a political party\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1081s\u001b[0m 315s/step - loss: 1597.7268 - val_loss: 1132.6705\n"
     ]
    }
   ],
   "source": [
    "#specifying the number of epochs for training \n",
    "epochs = 1\n",
    "#calling the custom Callbackeval function \n",
    "validation_callback = CallbackEval(test_dataset)\n",
    "#training the model using the fit function in keras\n",
    "history = model.fit(train_dataset, validation_data= test_dataset, epochs= epochs, callbacks = [validation_callback],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fad3ef3a-f228-488c-921f-f510f4e6fa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "....................................................................................................\n",
      "Word error rate :  1.0000\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "Printing random samples:\n",
      "Random Index: 30\n",
      "target :  the activities at parkland memorial hospital and the return of the presidential party to washington\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "Random Index: 56\n",
      "target :  he had repeated this wish only a few days before during his visit to tampa florida\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target : and therefore you are bound to furnish him with moderate indeed but suitable accommodation\n",
      "prediction:  \n",
      "....................................................................................................\n",
      "target : this was considered safer than intrusting him with keys\n",
      "prediction:  \n",
      "....................................................................................................\n"
     ]
    }
   ],
   "source": [
    "#checking for the predictions in the test_dataset \n",
    "predictions = []\n",
    "targets = []\n",
    "for batch in test_dataset :\n",
    "  X, y = batch\n",
    "  batch_predictions = model.predict(X)\n",
    "  batch_predictions = decode_batch_predictions (batch_predictions)\n",
    "  predictions.extend(batch_predictions)\n",
    "  for label in y :\n",
    "       label = (tf.strings.reduce_join (num_to_char(label)).numpy().decode(\"utf-8\"))\n",
    "       targets.append (label)\n",
    "wer_score = wer (targets, predictions)\n",
    "print (\".\" *100)\n",
    "print (f\"Word error rate : { wer_score: .4f}\")\n",
    "print (\".\"*100)\n",
    "print (\".\" *100)\n",
    "# Check if the loop is being executed\n",
    "print(\"Printing random samples:\")\n",
    "for i in range(2):\n",
    "    random_index = np.random.randint(0, len(predictions))\n",
    "    print(\"Random Index:\", random_index)\n",
    "    print(\"target : \", (targets[random_index]))\n",
    "    print(\"prediction: \", (predictions[random_index]))\n",
    "    print(\".\" * 100)\n",
    "for i in np.random.randint (0, len(predictions),2):\n",
    "      print (f\"target : {targets[i]}\")\n",
    "      print (f\"prediction:  {predictions[i]}\")\n",
    "      print (\".\" *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b9b7857-734d-4d37-b6a2-5915a73f2c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model and its assets\n",
    "model.save(\"stt.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6cdec86-7fdb-4f2f-b710-7279186939ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ASUS'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
